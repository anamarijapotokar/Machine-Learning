This repository contains my assignments and projects completed during a one-semester university course on Machine Learning (ITAP â€“ Izbrana poglavja iz analize podatkov / Selected Topics in Data Analysis). Each assignment explores different machine learning techniques ranging from basic models to advanced deep learning methods. Below is a summary of the contents and the main methods used in each assignment.

## Assignment 1

In this assignment, I implemented linear regression from scratch and confirmed that the recovered coefficients matched expected values when the target variable was a known linear combination of features. To address instability due to multicollinearity, I applied Ridge regression, which significantly reduced the variance of coefficient estimates. I also analyzed the correlation matrix of the features, visualized dependencies, and removed the most correlated ones to improve model reliability. In the second part, I built and evaluated k-Nearest Neighbors classifiers for predicting air quality levels. I optimized the number of neighbors k using cross-validation, tested distance-based weighting, and assessed the impact of removing non-informative or redundant features, which led to improved classification accuracy.

## Assignment 2

This assignment began with a model selection task, where I proposed suitable models for various datasets and decision scenarios. I then implemented a linear Support Vector Machine classifier, visualized the decision boundary, and verified classification logic manually. I continued by coding a simplified SVM-inspired learning algorithm that updated the decision boundary iteratively based on support vectors. Recognizing the limitations of linear models on nonlinearly separable data, I extended the classifier using polynomial and RBF kernels, which significantly improved accuracy on circularly distributed data. In the final task, I designed and trained a Convolutional Neural Network for facial emotion recognition. I experimented with data preprocessing, class rebalancing, weighted loss functions, and data augmentation. Through these iterations, I explored the trade-offs between class-specific accuracy and overall model performance, especially in the presence of class imbalance and visually ambiguous emotions.

## Assignment 3

In the third assignment, I began by analyzing different linkage criteria in hierarchical clustering and interpreting the resulting dendrograms in terms of compactness and separation. I then applied Linear Discriminant Analysis to digit recognition data, calculated scatter matrices, and projected the data into a lower-dimensional space to improve class separability. The results were compared with Principal Component Analysis, showing that LDA preserved class-relevant structure more effectively. I also visualized reconstructions to illustrate information loss in both methods. Finally, I built a multi-class classification model to predict student status (Graduate, Enrolled, Dropout) from demographic and academic features. I tested logistic regression, decision trees, random forests, and later improved performance through feature scaling, class balancing using SMOTE, and applying XGBoost. Each enhancement was evaluated using metrics such as accuracy, F1-score, and confusion matrices.
